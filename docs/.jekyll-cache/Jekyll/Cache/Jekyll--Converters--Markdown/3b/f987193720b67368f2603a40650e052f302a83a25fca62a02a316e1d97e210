I"†‰<h1 id="vector-api">Vector API</h1>

<h2 id="vectorized-environments">Vectorized Environments</h2>

<p><em>Vectorized environments</em> are environments that run multiple (independent) sub-environments, either sequentially, or in parallel using <a href="https://docs.python.org/3/library/multiprocessing.html">multiprocessing</a>. Vectorized environments take as input a batch of actions, and return a batch of observations. This is particularly useful, for example, when the policy is defined as a neural network that operates over a batch of observations.</p>

<p>Gym provides two types of vectorized environments:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- `gym.vector.SyncVectorEnv`, where the sub-environment are executed sequentially.
- `gym.vector.AsyncVectorEnv`, where the sub-environments are executed in parallel using [multiprocessing](https://docs.python.org/3/library/multiprocessing.html). This creates one process per sub-environment.
</code></pre></div></div>

<p>Similar to <code class="language-plaintext highlighter-rouge">gym.make</code>, you can run a vectorized version of a registered environment using the <code class="language-plaintext highlighter-rouge">gym.vector.make</code> function. This runs multiple copies of the same environment (in parallel, by default).</p>

<p>The following example runs 3 copies of the <code class="language-plaintext highlighter-rouge">CartPole-v1</code> environment in parallel, taking as input a vector of 3 binary actions (one for each sub-environment), and returning an array of 3 observations stacked along the first dimension, with an array of rewards returned by each sub-environment, and an array of booleans indicating if the episode in each sub-environment has ended.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">envs</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">vector</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">,</span> <span class="n">num_envs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">envs</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">observations</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">envs</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">observations</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">0.00122802</span><span class="p">,</span>  <span class="mf">0.16228443</span><span class="p">,</span>  <span class="mf">0.02521779</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23700266</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.00788269</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17490888</span><span class="p">,</span>  <span class="mf">0.03393489</span><span class="p">,</span>  <span class="mf">0.31735462</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.04918966</span><span class="p">,</span>  <span class="mf">0.19421194</span><span class="p">,</span>  <span class="mf">0.02938497</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.29495203</span><span class="p">]],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rewards</span>
<span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dones</span>
<span class="n">array</span><span class="p">([</span><span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">infos</span>
<span class="p">({},</span> <span class="p">{},</span> <span class="p">{})</span>
</code></pre></div></div>

<p>The function <code class="language-plaintext highlighter-rouge">gym.vector.make</code> is meant to be used only in basic cases (e.g. running multiple copies of the same registered environment). For any other use-cases, please use either the <code class="language-plaintext highlighter-rouge">SyncVectorEnv</code> for sequential execution, or <code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code> for parallel execution. These use-cases may include:</p>

<ul>
  <li>Running multiple instances of the same environment with different parameters (e.g. <code class="language-plaintext highlighter-rouge">"Pendulum-v0"</code> with different values for the gravity).</li>
  <li>Running multiple instances of an unregistered environment (e.g. a custom environment)</li>
  <li>Using a wrapper on some (but not all) sub-environments.</li>
</ul>

<h3 id="creating-a-vectorized-environment">Creating a vectorized environment</h3>

<p>To create a vectorized environment that runs multiple sub-environments, you can wrap your sub-environments inside <code class="language-plaintext highlighter-rouge">gym.vector.SyncVectorEnv</code> (for sequential execution), or <code class="language-plaintext highlighter-rouge">gym.vector.AsyncVectorEnv</code> (for parallel execution, with <a href="https://docs.python.org/3/library/multiprocessing.html">multiprocessing</a>). These vectorized environments take as input a list of callable specifying how the sub-environments are created.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">envs</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">vector</span><span class="p">.</span><span class="n">AsyncVectorEnv</span><span class="p">([</span>
<span class="p">...</span>     <span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">),</span>
<span class="p">...</span>     <span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">),</span>
<span class="p">...</span>     <span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">)</span>
<span class="p">...</span> <span class="p">])</span>
</code></pre></div></div>

<p>Alternatively, to create a vectorized environment of multiple copies of the same registered sub-environment, you can use the function :func:<code class="language-plaintext highlighter-rouge">gym.vector.make</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">envs</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">vector</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">,</span> <span class="n">num_envs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Equivalent
</span></code></pre></div></div>

<p>To enable automatic batching of actions and observations, all the sub-environments must share the same :obj:<code class="language-plaintext highlighter-rouge">action_space</code> and :obj:<code class="language-plaintext highlighter-rouge">observation_space</code>. However, all the sub-environments are not required to be exact copies of one another. For example, you can run 2 instances of <code class="language-plaintext highlighter-rouge">Pendulum-v0</code> with different values of the gravity in a vectorized environment with</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">vector</span><span class="p">.</span><span class="n">AsyncVectorEnv</span><span class="p">([</span>
<span class="p">...</span>     <span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"Pendulum-v0"</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mf">9.81</span><span class="p">),</span>
<span class="p">...</span>     <span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"Pendulum-v0"</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mf">1.62</span><span class="p">)</span>
<span class="p">...</span> <span class="p">])</span>
</code></pre></div></div>

<p>See also <code class="language-plaintext highlighter-rouge">Observation &amp; Action spaces</code> for more information about automatic batching.</p>

<p>When using <code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code> with either the <code class="language-plaintext highlighter-rouge">spawn</code> or <code class="language-plaintext highlighter-rouge">forkserver</code> start methods, you must wrap your code containing the vectorized environment with <code class="language-plaintext highlighter-rouge">if __name__ == "__main__":</code>. See <a href="https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods">this documentation</a> for more information.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">envs</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">vector</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">,</span> <span class="n">num_envs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="s">"spawn"</span><span class="p">)</span>
</code></pre></div></div>
<h3 id="working-with-vectorized-environments">Working with vectorized environments</h3>

<p>While standard Gym environments take a single action and return a single observation (with a reward, and boolean indicating termination), vectorized environments take a <em>batch of actions</em> as input, and return a <em>batch of observations</em>, together with an array of rewards and booleans indicating if the episode ended in each sub-environment.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.reset()
array([[ 0.00198895, -0.00569421, -0.03170966,  0.00126465],
       [-0.02658334,  0.00755256,  0.04376719, -0.00266695],
       [-0.02898625,  0.04779156,  0.02686412, -0.01298284]],
      dtype=float32)

&gt;&gt;&gt; actions = np.array([1, 0, 1])
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(actions)

&gt;&gt;&gt; observations
array([[ 0.00187507,  0.18986781, -0.03168437, -0.301252  ],
       [-0.02643229, -0.18816885,  0.04371385,  0.3034975 ],
       [-0.02803041,  0.24251814,  0.02660446, -0.29707024]],
      dtype=float32)
&gt;&gt;&gt; rewards
array([1., 1., 1.])
&gt;&gt;&gt; dones
array([False, False, False])
&gt;&gt;&gt; infos
({}, {}, {})
</code></pre></div></div>

<p>Vectorized environments are compatible with any sub-environment, regardless of the action and observation spaces (e.g. container spaces like <code class="language-plaintext highlighter-rouge">gym.spaces.Dict</code>, or any arbitrarily nested spaces). In particular, vectorized environments can automatically batch the observations returned by :meth:<code class="language-plaintext highlighter-rouge">VectorEnv.reset</code> and :meth:<code class="language-plaintext highlighter-rouge">VectorEnv.step</code> for any standard Gym space (e.g. <code class="language-plaintext highlighter-rouge">gym.spaces.Box</code>, <code class="language-plaintext highlighter-rouge">gym.spaces.Discrete</code>, <code class="language-plaintext highlighter-rouge">gym.spaces.Dict</code>, or any nested structure thereof). Similarly, vectorized environments can take batches of actions from any standard Gym space.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; class DictEnv(gym.Env):
...     observation_space = gym.spaces.Dict({
...         "position": gym.spaces.Box(-1., 1., (3,), np.float32),
...         "velocity": gym.spaces.Box(-1., 1., (2,), np.float32)
...     })
...     action_space = gym.spaces.Dict({
...         "fire": gym.spaces.Discrete(2),
...         "jump": gym.spaces.Discrete(2),
...         "acceleration": gym.spaces.Box(-1., 1., (2,), np.float32)
...     })
...
...     def reset(self):
...         return self.observation_space.sample()
...
...     def step(self, action):
...         observation = self.observation_space.sample()
...         return (observation, 0., False, {})

&gt;&gt;&gt; envs = gym.vector.AsyncVectorEnv([lambda: DictEnv()] * 3)
&gt;&gt;&gt; envs.observation_space
Dict(position:Box(-1.0, 1.0, (3, 3), float32), velocity:Box(-1.0, 1.0, (3, 2), float32))
&gt;&gt;&gt; envs.action_space
Dict(fire:MultiDiscrete([2 2 2]), jump:MultiDiscrete([2 2 2]), acceleration:Box(-1.0, 1.0, (3, 2), float32))

&gt;&gt;&gt; envs.reset()
&gt;&gt;&gt; actions = {
...     "fire": np.array([1, 1, 0]),
...     "jump": np.array([0, 1, 0]),
...     "acceleration": np.random.uniform(-1., 1., size=(3, 2))
... }
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(actions)
&gt;&gt;&gt; observations
{"position": array([[-0.5337036 ,  0.7439302 ,  0.41748118],
                    [ 0.9373266 , -0.5780453 ,  0.8987405 ],
                    [-0.917269  , -0.5888639 ,  0.812942  ]], dtype=float32),
"velocity": array([[ 0.23626241, -0.0616814 ],
                   [-0.4057572 , -0.4875375 ],
                   [ 0.26341468,  0.72282314]], dtype=float32)}
</code></pre></div></div>

<p>The sub-environments inside a vectorized environment automatically call :obj:<code class="language-plaintext highlighter-rouge">reset</code> at the end of an episode. In the following example, the episode of the 3rd sub-environment ends after 2 steps (the agent fell in a hole), and the sub-environment gets reset (observation <code class="language-plaintext highlighter-rouge">0</code>).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("FrozenLake-v1", num_envs=3, is_slippery=False)
&gt;&gt;&gt; envs.reset()
array([0, 0, 0])
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(np.array([1, 2, 2]))
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(np.array([1, 2, 1]))

&gt;&gt;&gt; dones
array([False, False,  True])
&gt;&gt;&gt; observations
array([8, 2, 0])
</code></pre></div></div>

<h3 id="observation--action-spaces">Observation &amp; Action spaces</h3>

<p>Like any Gym environment, vectorized environments contain two properties <code class="language-plaintext highlighter-rouge">VectorEnv.observation_space</code> and <code class="language-plaintext highlighter-rouge">VectorEnv.action_space</code> to specify the observation and action spaces of the environment. Since vectorized environments operate on multiple sub-environments, where the observations and actions of sub-environments are batched together, the observation and action spaces are adequately batched as well so that the input actions are valid elements of <code class="language-plaintext highlighter-rouge">VectorEnv.action_space</code>, and the observations are valid elements of <code class="language-plaintext highlighter-rouge">VectorEnv.observation_space</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.observation_space
Box([[-4.8 ...]], [[4.8 ...]], (3, 4), float32)
&gt;&gt;&gt; envs.action_space
MultiDiscrete([2 2 2])
</code></pre></div></div>

<p>In order to appropriately batch the observations and actions in vectorized environments, the observation and action spaces of all the sub-environments are required to be identical.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.AsyncVectorEnv([
...     lambda: gym.make("CartPole-v1"),
...     lambda: gym.make("MountainCar-v0")
... ])
RuntimeError: Some environments have an observation space different from `Box([-4.8 ...], [4.8 ...], (4,), float32)`. In order to batch observations, the observation spaces from all environments must be equal.
</code></pre></div></div>

<p>However, sometimes it may be handy to have access to the observation and action spaces of a sub-environment, and not the batched spaces. You can access those with the properties <code class="language-plaintext highlighter-rouge">VectorEnv.single_observation_space</code> and <code class="language-plaintext highlighter-rouge">VectorEnv.single_action_space</code> of the vectorized environment.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.single_observation_space
Box([-4.8 ...], [4.8 ...], (4,), float32)
&gt;&gt;&gt; envs.single_action_space
Discrete(2)
</code></pre></div></div>

<p>This is convenient, for example, if you instantiate a policy. In the following example, we used <code class="language-plaintext highlighter-rouge">VectorEnv.single_observation_space</code> and <code class="language-plaintext highlighter-rouge">VectorEnv.single_action_space</code> to define the weights of a linear policy. Note that thanks to the vectorized environment, you can apply the policy directly to the whole batch of observations with a single call to :obj:<code class="language-plaintext highlighter-rouge">policy</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; from gym.spaces.utils import flatdim
&gt;&gt;&gt; from scipy.special import softmax

&gt;&gt;&gt; def policy(weights, observations):
...     logits = np.dot(observations, weights)
...     return softmax(logits, axis=1)

&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; weights = np.random.randn(
...     flatdim(envs.single_observation_space),
...     envs.single_action_space.n
... )
&gt;&gt;&gt; observations = envs.reset()
&gt;&gt;&gt; actions = policy(weights, observations).argmax(axis=1)
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(actions)
</code></pre></div></div>

<h2 id="intermediate-usage">Intermediate Usage</h2>

<h3 id="shared-memory">Shared memory</h3>

<p><code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code> runs each sub-environment inside an individual process. At each call to :meth:<code class="language-plaintext highlighter-rouge">AsyncVectorEnv.reset</code> or :meth:<code class="language-plaintext highlighter-rouge">AsyncVectorEnv.step</code>, the observations of all the sub-environments are sent back to the main process. To avoid expensive transfers of data between processes, especially with large observations (e.g. images), <code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code> uses a shared memory by default (<code class="language-plaintext highlighter-rouge">shared_memory=True</code>) that processes can write to and read from at minimal cost. This can increase the throughout of the vectorized environment.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; env_fns = [lambda: gym.make("BreakoutNoFrameskip-v4")] * 5

&gt;&gt;&gt; envs = gym.vector.AsyncVectorEnv(env_fns, shared_memory=False)
&gt;&gt;&gt; envs.reset()
&gt;&gt;&gt; %timeit envs.step(envs.action_space.sample())
2.23 ms Â± 136 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)

&gt;&gt;&gt; envs = gym.vector.AsyncVectorEnv(env_fns, shared_memory=True)
&gt;&gt;&gt; envs.reset()
&gt;&gt;&gt; %timeit envs.step(envs.action_space.sample())
1.36 ms Â± 15.4 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)
</code></pre></div></div>

<h3 id="exception-handling">Exception handling</h3>

<p>Because sometimes things may not go as planned, the exceptions raised in sub-environments are re-raised in the vectorized environment, even when the sub-environments run in parallel with <code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code>. This way, you can choose how to handle these exceptions yourself (with <code class="language-plaintext highlighter-rouge">try ... except</code>).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; class ErrorEnv(gym.Env):
...     observation_space = gym.spaces.Box(-1., 1., (2,), np.float32)
...     action_space = gym.spaces.Discrete(2)
...
...     def reset(self):
...         return np.zeros((2,), dtype=np.float32)
...
...     def step(self, action):
...         if action == 1:
...             raise ValueError("An error occurred.")
...         observation = self.observation_space.sample()
...         return (observation, 0., False, {})

&gt;&gt;&gt; envs = gym.vector.AsyncVectorEnv([lambda: ErrorEnv()] * 3)
&gt;&gt;&gt; observations = envs.reset()
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(np.array([0, 0, 1]))
ERROR: Received the following error from Worker-2: ValueError: An error occurred.
ERROR: Shutting down Worker-2.
ERROR: Raising the last exception back to the main process.
ValueError: An error occurred.
</code></pre></div></div>

<h2 id="advanced-usage">Advanced Usage</h2>

<h3 id="custom-spaces">Custom spaces</h3>

<p>Vectorized environments will batch actions and observations if they are elements from standard Gym spaces, such as <code class="language-plaintext highlighter-rouge">gym.spaces.Box</code>, <code class="language-plaintext highlighter-rouge">gym.spaces.Discrete</code>, or <code class="language-plaintext highlighter-rouge">gym.spaces.Dict</code>. If you create your own environment with a custom action and/or observation space though (inheriting from <code class="language-plaintext highlighter-rouge">gym.Space</code>), the vectorized environment will not attempt to automatically batch the actions/observations, and instead it will return the raw tuple of elements from all sub-environments.</p>

<p>In the following example, we created a new environment <code class="language-plaintext highlighter-rouge">SMILESEnv</code>, whose observations are strings representing the <a href="https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system">SMILES</a> notation of a molecular structure, with a custom observation space <code class="language-plaintext highlighter-rouge">SMILES</code>. The observations returned by the vectorized environment is a tuple of strings.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">SMILES</span><span class="p">(</span><span class="n">gym</span><span class="p">.</span><span class="n">Space</span><span class="p">):</span>
<span class="p">...</span>     <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">symbols</span><span class="p">):</span>
<span class="p">...</span>         <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
<span class="p">...</span>         <span class="bp">self</span><span class="p">.</span><span class="n">symbols</span> <span class="o">=</span> <span class="n">symbols</span>
<span class="p">...</span>
<span class="p">...</span>     <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
<span class="p">...</span>         <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">symbols</span> <span class="o">==</span> <span class="n">other</span><span class="p">.</span><span class="n">symbols</span>

<span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">SMILESEnv</span><span class="p">(</span><span class="n">gym</span><span class="p">.</span><span class="n">Env</span><span class="p">):</span>
<span class="p">...</span>     <span class="n">observation_space</span> <span class="o">=</span> <span class="n">SMILES</span><span class="p">(</span><span class="s">"][()CO="</span><span class="p">)</span>
<span class="p">...</span>     <span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">spaces</span><span class="p">.</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="p">...</span>
<span class="p">...</span>     <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="p">...</span>         <span class="bp">self</span><span class="p">.</span><span class="n">_state</span> <span class="o">=</span> <span class="s">"["</span>
<span class="p">...</span>         <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_state</span>
<span class="p">...</span>
<span class="p">...</span>     <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
<span class="p">...</span>         <span class="bp">self</span><span class="p">.</span><span class="n">_state</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">symbols</span><span class="p">[</span><span class="n">action</span><span class="p">]</span>
<span class="p">...</span>         <span class="n">reward</span> <span class="o">=</span> <span class="n">done</span> <span class="o">=</span> <span class="p">(</span><span class="n">action</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">...</span>         <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_state</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">reward</span><span class="p">),</span> <span class="n">done</span><span class="p">,</span> <span class="p">{})</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">envs</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">vector</span><span class="p">.</span><span class="n">AsyncVectorEnv</span><span class="p">(</span>
<span class="p">...</span>     <span class="p">[</span><span class="k">lambda</span><span class="p">:</span> <span class="n">SMILESEnv</span><span class="p">()]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">...</span>     <span class="n">shared_memory</span><span class="o">=</span><span class="bp">False</span>
<span class="p">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">envs</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">observations</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">envs</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">observations</span>
<span class="p">(</span><span class="s">'[('</span><span class="p">,</span> <span class="s">'[O'</span><span class="p">,</span> <span class="s">'[C'</span><span class="p">)</span>
</code></pre></div></div>

<p>Custom observation &amp; action spaces may inherit from the <code class="language-plaintext highlighter-rouge">gym.Space</code> class. However, most use-cases should be covered by the existing space classes (e.g. <code class="language-plaintext highlighter-rouge">gym.spaces.Box</code>, <code class="language-plaintext highlighter-rouge">gym.spaces.Discrete</code>, etcâ€¦), and container classes (<code class="language-plaintext highlighter-rouge">gym.spaces.Tuple</code> &amp; <code class="language-plaintext highlighter-rouge">gym.spaces.Dict</code>). Moreover, some implementations of Reinforcement Learning algorithms might not handle custom spaces properly. Use custom spaces with care.</p>

<p>If you use <code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code> with a custom observation space, you must set <code class="language-plaintext highlighter-rouge">shared_memory=False</code>, since shared memory and automatic batching is not compatible with custom spaces. In general if you use custom spaces with <code class="language-plaintext highlighter-rouge">AsyncVectorEnv</code>, the elements of those spaces must be <code class="language-plaintext highlighter-rouge">pickleable</code>_.</p>

<h2 id="api-reference">API Reference</h2>

<h3 id="vectorenv">VectorEnv</h3>

<p>The (batched) action space. The input actions of <code class="language-plaintext highlighter-rouge">step</code> must be valid elements of <code class="language-plaintext highlighter-rouge">action_space</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.action_space
MultiDiscrete([2 2 2])
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">gym.spaces.Space</code></p>

<p>The (batched) observation space. The observations returned by :meth:<code class="language-plaintext highlighter-rouge">reset</code> and :meth:<code class="language-plaintext highlighter-rouge">step</code> are valid elements of <code class="language-plaintext highlighter-rouge">observation_space</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.observation_space
Box([[-4.8 ...]], [[4.8 ...]], (3, 4), float32)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">gym.spaces.Space</code></p>

<p>The action space of a sub-environment.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.single_action_space
Discrete(2)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">gym.spaces.Space</code></p>

<p>The observation space of a sub-environment.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.single_action_space
Box([-4.8 ...], [4.8 ...], (4,), float32)
</code></pre></div></div>

<h3 id="reset">Reset</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.reset()
array([[-0.04456399,  0.04653909,  0.01326909, -0.02099827],
        [ 0.03073904,  0.00145001, -0.03088818, -0.03131252],
        [ 0.03468829,  0.01500225,  0.01230312,  0.01825218]],
        dtype=float32)
</code></pre></div></div>

<h3 id="step">Step</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.reset()
&gt;&gt;&gt; actions = np.array([1, 0, 1])
&gt;&gt;&gt; observations, rewards, dones, infos = envs.step(actions)

&gt;&gt;&gt; observations
array([[ 0.00122802,  0.16228443,  0.02521779, -0.23700266],
        [ 0.00788269, -0.17490888,  0.03393489,  0.31735462],
        [ 0.04918966,  0.19421194,  0.02938497, -0.29495203]],
        dtype=float32)
&gt;&gt;&gt; rewards
array([1., 1., 1.])
&gt;&gt;&gt; dones
array([False, False, False])
&gt;&gt;&gt; infos
({}, {}, {})
</code></pre></div></div>

<h3 id="seed">Seed</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; envs = gym.vector.make("CartPole-v1", num_envs=3)
&gt;&gt;&gt; envs.seed([1, 3, 5])
&gt;&gt;&gt; envs.reset()
array([[ 0.03073904,  0.00145001, -0.03088818, -0.03131252],
        [ 0.02281231, -0.02475473,  0.02306162,  0.02072129],
        [-0.03742824, -0.02316945,  0.0148571 ,  0.0296055 ]],
        dtype=float32)
</code></pre></div></div>
:ET